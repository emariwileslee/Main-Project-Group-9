{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Libraries\n",
    "from PIL import Image\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re,string,unicodedata\n",
    "import cv2\n",
    "import requests\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "#Tesseract Library\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "\n",
    "#Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Garbage Collection\n",
    "import gc\n",
    "\n",
    "#Gensim Library for Text Processing\n",
    "import gensim.parsing.preprocessing as gsp\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim import utils\n",
    "\n",
    "#TextBlob Library (Sentiment Analysis)\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "#Plotting Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Directory Path\n",
    "#sample_images = r'C:\\Users\\calli\\Downloads\\train_images'\n",
    "test_images = r'C:\\Users\\calli\\Documents\\MATLAB\\archive\\bow_sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Function to Traverse the folder\n",
    "def traverse(directory):\n",
    "    path, dirs, files = next(os.walk(directory))\n",
    "    fol_nm = os.path.split(os.path.dirname(path))[-1]\n",
    "    print(f'Number of files found in \"{fol_nm}\" : ',len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files found in \"archive\" :  10\n"
     ]
    }
   ],
   "source": [
    "#Traversing the folders\n",
    "#traverse(sample_images)\n",
    "traverse(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_txt = []   #list to store the extracted text\n",
    "txt4bow = [] #list to use for bag of words\n",
    "\n",
    "#Function to Extract Text\n",
    "def TxtExtract(directory):\n",
    "    \"\"\"\n",
    "    This function will handle the core OCR processing of images.\n",
    "    \"\"\"\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            filepath = subdir + os.sep + file\n",
    "            \n",
    "            img_cv = cv2.imread(filepath)\n",
    "            img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            text = pytesseract.image_to_string(img_rgb)\n",
    "            \n",
    "            x = re.sub(r'\\n{2, 10}', '\\n', text)\n",
    "            \n",
    "            ifspace = text.isspace()\n",
    "            if ifspace == True:\n",
    "                print(file)\n",
    "                print(\"image does not have text\")\n",
    "            else:   \n",
    "                print(file)\n",
    "                ex_txt.extend([[file, filepath, (x.rstrip(\"\\n\"))]])\n",
    "                txt4bow.extend([text])\n",
    "                print(x.rstrip(\"\\n\"))\n",
    "                \n",
    "    fol_nm = os.path.split(os.path.dirname(subdir))[-1]\n",
    "    \n",
    "    print(f\"Text Extracted from the files in '{fol_nm}' folder & saved to list..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37760088-9125741-image-a-4_1610103049128.jpg\n",
      "Lisa Wilkinson\n",
      "@Lisa_Wilkinson\n",
      "\n",
      "The Simpons’ ability to predict the future is now\n",
      "Officially out of control.\n",
      "\n",
      "Can | request a nice episode that has Michelle Obama\n",
      "as President sometime soon please?\n",
      "\n",
      " \n",
      "\n",
      "9:49 AM - Jan 8, 2021 - Twitter for iPad\n",
      "\f",
      "\n",
      "37767688-0-image-a-8_1610117767171.jpg\n",
      " \n",
      " \n",
      "   \n",
      "\n",
      "y. A\n",
      "\n",
      "oing to steal|the|Declaration of Independence:\n",
      "\n",
      "  \n",
      "\n",
      "When you riotice that all the cops in\n",
      "Washington DC are distracted by rioters.\n",
      "\f",
      "\n",
      "486.png\n",
      "image does not have text\n",
      "c0y4dmy5by961.jpg\n",
      "The protesters making their\n",
      "way inside the Capital\n",
      "Building after being shot at,\n",
      "maced, beaten, tear gased,\n",
      "and tased :\n",
      "\n",
      " \n",
      "\f",
      "\n",
      "images-47-1.jpeg\n",
      "ey\n",
      "WITHIN THE BOUNDS OF THE LAW,\n",
      "\n",
      ">\n",
      "\n",
      "  \n",
      "\n",
      "|\n",
      "‘ir 77\n",
      "\n",
      "TO KEEP AMER ich SAFE! :\n",
      "\f",
      "\n",
      "images.jfif\n",
      "Future: How Do You Want Us To Remember The\n",
      "Capitol Hil Riots?\n",
      "Social Studios Text Books:\n",
      "\n",
      " \n",
      "\f",
      "\n",
      "same-cheese-bloodbuzz-me-to-my-son-via-getty-youre-named-after-something-that-was-so-fucking-funny.jfif\n",
      " \n",
      "\n",
      "PY Ryan Liza @\n",
      "anLizza\n",
      "\n",
      "To be clear, “via Getty\" is not a person.\n",
      "It just means that this photo comes via\n",
      "Getty Images.\n",
      "\n",
      "charles new year same cheese\n",
      "@bloodbuzz\n",
      "\n",
      "Me (to my son): Via Getty, you're named\n",
      "after something that was so fix “ing\n",
      "funny\n",
      "\n",
      " \n",
      "\f",
      "\n",
      "thumb_156482140_100682365398804_6003463500052117241_n-7463519634.jpg\n",
      "ng January 6th:\n",
      "Republicans push false and\n",
      "misleading accounts of\n",
      "Capi\n",
      "\n",
      "nt Donald Trump who\n",
      "infor The\n",
      "\n",
      " \n",
      "\f",
      "\n",
      "trump.jpg\n",
      "e ELIJAH SCHAFFER\n",
      "GoP@ culiaid\n",
      "\n",
      "p BREAKING: | am inside Nancy\n",
      "Pelosi's office with the thousands\n",
      "of revolutionaries who have\n",
      "\n",
      "= stormed the building\n",
      "\n",
      "t's simple: Walls work,\n",
      "\n",
      "To put into perspective how\n",
      "quickly staff evacuated, emails\n",
      "are still on the screen along side\n",
      "\n",
      "3.4K 286 5.7K\n",
      "\n",
      " \n",
      "\f",
      "\n",
      "ysd6gyksux961.jpg\n",
      "> | |\n",
      "PAN a ais) dors)\n",
      "\n",
      "   \n",
      " \n",
      "\n",
      "Why are you’ doing this?,\n",
      "\n",
      "rAVanis) (Orca\n",
      "\n",
      "= i i gh.\n",
      "?\n",
      "\n",
      "y{olUKe|(e! this to yourself\n",
      "\f",
      "\n",
      "Text Extracted from the files in 'archive' folder & saved to list..\n"
     ]
    }
   ],
   "source": [
    "#Extracting Text from JPG files in Sample Image Folder\n",
    "#TxtExtract(sample_images)\n",
    "\n",
    "#Extracting Text from JPG files in Dataset Folder\n",
    "TxtExtract(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OCR.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    header = ['FileName', 'Filepath', 'Text']\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(ex_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys: ['the', 'to', 'getty', 'lisa', 'wilkinson', 'future', 'y', 'inside', 'building', 'e', 'simpons’', 'ability', 'predict', 'officially', 'control', 'can', 'request', 'nice', 'episode', 'michelle', 'obama', 'president', 'soon', 'please', '9', '49', 'am', 'jan', '8', '2021', 'twitter', 'ipad', 'a', 'oing', 'steal', 'declaration', 'independence', 'when', 'riotice', 'cops', 'washington', 'dc', 'distracted', 'rioters', 'protesters', 'making', 'way', 'capital', 'shot', 'at', 'maced', 'beaten', 'tear', 'gased', 'tased', 'ey', 'within', 'bounds', 'of', 'law', '‘ir', '77', 'keep', 'amer', 'ich', 'safe', 'how', 'do', 'you', 'want', 'us', 'remember', 'capitol', 'hil', 'riots', 'social', 'studios', 'text', 'books', 'py', 'ryan', 'liza', 'anlizza', 'clear', '“via', 'person', 'it', 'means', 'photo', 'comes', 'images', 'charles', 'new', 'year', 'cheese', 'bloodbuzz', 'me', 'son', 'via', \"you're\", 'named', 'fix', '“ing', 'funny', 'ng', 'january', '6th', 'republicans', 'push', 'false', 'misleading', 'accounts', 'capi', 'nt', 'donald', 'trump', 'infor', 'elijah', 'schaffer', 'gop', 'culiaid', 'p', 'breaking', 'nancy', \"pelosi's\", 'office', 'thousands', 'revolutionaries', 'stormed', \"t's\", 'simple', 'walls', 'work', 'perspective', 'quickly', 'staff', 'evacuated', 'emails', 'screen', '3', '4k', '286', '5', '7k', 'pan', 'ais', 'dors', 'why', 'you’', 'this', 'ravanis', 'orca', 'gh', 'oluke']\n",
      "\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#BOW\n",
    "\n",
    "filtered_txt = []\n",
    "\n",
    "for n in range(len(txt4bow)):\n",
    "    #remove stopwords\n",
    "    filtered_sentence = remove_stopwords(txt4bow[n])\n",
    "    filtered_txt.extend([filtered_sentence])\n",
    "\n",
    "\n",
    "\n",
    "# using tokenizer \n",
    "model = Tokenizer()\n",
    "model.fit_on_texts(filtered_txt)\n",
    "\n",
    "keys = model.word_index.keys()\n",
    "\n",
    "#print keys \n",
    "print(f'keys: {list(keys)}\\n')\n",
    "\n",
    "#create bag of words representation \n",
    "rep = model.texts_to_matrix(filtered_txt, mode='count')\n",
    "print(rep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BOW.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    header = [keys]\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Free up memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
